defaults:
  - loss: mr_loss   # override this to melstft_loss if you are using MelSTFTLoss, or stft_loss if you are using STFTLoss as lossfn
#  - loss: stft_loss

batch_size: 32
learning_rate: 0.00001
max_epochs: 90
check_val_every_n_epoch: 10
accelerator: cuda # "cpu", "cuda", "mps"
num_workers: 6 # number of workers for training dataloader
continue_test: false  # Proceed to run testing set if True after epochs is completed

# Do note to change the above defaults loss if using STFTLoss, or MultiResolutionSTFTLoss
lossfn: 'MSELoss' # error_to_signal, ESRLoss, DCLoss, LogCoshLoss, SNRLoss, SDSDRLoss, MSELoss, DC_SDSDR_SNR_Loss, STFTLoss, MelSTFTLoss, MultiResolutionSTFTLoss, RandomResolutionSTFTLoss, EMBLoss, EMB_MR_Loss, EMB_MSE_Loss


loss_preemphasis_hp_filter: false
loss_preemphasis_hp_coeff: 0.95
loss_preemphasis_aw_filter: false


experiment_name: 'waveunet_MSELoss'


resume_checkpoint: false
checkpoint_file: './outputs/2023-03-22/08-05-43/models/auto2_freeze_EMB_MSE_Loss.ckpt'

use_checkpoint_callback: true
model_checkpoint_path: './models/'

use_mlflow: true
tracking_uri: './mlruns'